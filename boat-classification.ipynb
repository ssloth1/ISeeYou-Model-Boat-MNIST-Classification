{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# James Bebarski\n",
    "# Computer Vision\n",
    "# Boat MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boats(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, gt_json_path=''):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.gt_json_path = gt_json_path\n",
    "        self.labels = json.load(open(gt_json_path, 'r'))\n",
    "        self.image_list = sorted(os.listdir(root_dir))\n",
    "        self.image_ids = dict(enumerate(self.image_list, start=0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.load_image(idx)\n",
    "        img_name = self.image_ids[idx]\n",
    "        label = self.labels[img_name]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        sample = (img, label)\n",
    "        return sample\n",
    "\n",
    "    def load_image(self, image_index):\n",
    "        image_name = self.image_ids[image_index]\n",
    "        path = os.path.join(self.root_dir, image_name)\n",
    "        img = imread(path)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(512 * 6 * 12, 512)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, criterion, epoch,dry_run):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.unsqueeze(target, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    misclassified_images = []\n",
    "    misclassified_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device).float()\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, torch.unsqueeze(target, 1)).item()\n",
    "            pred = torch.round(output)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            incorrect_indices = (pred != target.view_as(pred)).nonzero(as_tuple=True)[0]\n",
    "            misclassified_images.extend(data[incorrect_indices].cpu())\n",
    "            misclassified_labels.extend(target[incorrect_indices].cpu())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def save_my_model(model, path):\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    torch.save(model.state_dict(), path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 20428289\n",
      "Train Epoch: 1 [0/3765 (0%)]\tLoss: 0.692264\n",
      "Train Epoch: 1 [640/3765 (17%)]\tLoss: 7.938241\n",
      "Train Epoch: 1 [1280/3765 (34%)]\tLoss: 3.380338\n",
      "Train Epoch: 1 [1920/3765 (51%)]\tLoss: 6.525831\n",
      "Train Epoch: 1 [2560/3765 (68%)]\tLoss: 4.972595\n",
      "Train Epoch: 1 [3200/3765 (85%)]\tLoss: 0.010077\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 1401/1506 (93%)\n",
      "\n",
      "New best model saved with accuracy: 93.02788844621514\n",
      "Train Epoch: 2 [0/3765 (0%)]\tLoss: 3.217345\n",
      "Train Epoch: 2 [640/3765 (17%)]\tLoss: 4.908980\n",
      "Train Epoch: 2 [1280/3765 (34%)]\tLoss: 1.729184\n",
      "Train Epoch: 2 [1920/3765 (51%)]\tLoss: 3.304161\n",
      "Train Epoch: 2 [2560/3765 (68%)]\tLoss: 5.076772\n",
      "Train Epoch: 2 [3200/3765 (85%)]\tLoss: 4.758737\n",
      "\n",
      "Test set: Average loss: 0.0046, Accuracy: 1444/1506 (96%)\n",
      "\n",
      "New best model saved with accuracy: 95.88313413014608\n",
      "Train Epoch: 3 [0/3765 (0%)]\tLoss: 1.790873\n",
      "Train Epoch: 3 [640/3765 (17%)]\tLoss: 7.867572\n",
      "Train Epoch: 3 [1280/3765 (34%)]\tLoss: 0.016977\n",
      "Train Epoch: 3 [1920/3765 (51%)]\tLoss: 3.131707\n",
      "Train Epoch: 3 [2560/3765 (68%)]\tLoss: 1.693389\n",
      "Train Epoch: 3 [3200/3765 (85%)]\tLoss: 1.676389\n",
      "\n",
      "Test set: Average loss: 0.0047, Accuracy: 1442/1506 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/3765 (0%)]\tLoss: 1.753305\n",
      "Train Epoch: 4 [640/3765 (17%)]\tLoss: 4.904776\n",
      "Train Epoch: 4 [1280/3765 (34%)]\tLoss: 4.954350\n",
      "Train Epoch: 4 [1920/3765 (51%)]\tLoss: 0.000217\n",
      "Train Epoch: 4 [2560/3765 (68%)]\tLoss: 0.334977\n",
      "Train Epoch: 4 [3200/3765 (85%)]\tLoss: 0.117886\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 1475/1506 (98%)\n",
      "\n",
      "New best model saved with accuracy: 97.94156706507304\n",
      "Train Epoch: 5 [0/3765 (0%)]\tLoss: 0.848933\n",
      "Train Epoch: 5 [640/3765 (17%)]\tLoss: 0.019993\n",
      "Train Epoch: 5 [1280/3765 (34%)]\tLoss: 0.009495\n",
      "Train Epoch: 5 [1920/3765 (51%)]\tLoss: 1.794297\n",
      "Train Epoch: 5 [2560/3765 (68%)]\tLoss: 0.536690\n",
      "Train Epoch: 5 [3200/3765 (85%)]\tLoss: 1.851409\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1429/1506 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/3765 (0%)]\tLoss: 0.123155\n",
      "Train Epoch: 6 [640/3765 (17%)]\tLoss: 0.018240\n",
      "Train Epoch: 6 [1280/3765 (34%)]\tLoss: 0.206350\n",
      "Train Epoch: 6 [1920/3765 (51%)]\tLoss: 0.006983\n",
      "Train Epoch: 6 [2560/3765 (68%)]\tLoss: 0.018617\n",
      "Train Epoch: 6 [3200/3765 (85%)]\tLoss: 1.564945\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 1481/1506 (98%)\n",
      "\n",
      "New best model saved with accuracy: 98.33997343957503\n",
      "Train Epoch: 7 [0/3765 (0%)]\tLoss: 0.021878\n",
      "Train Epoch: 7 [640/3765 (17%)]\tLoss: 0.005852\n",
      "Train Epoch: 7 [1280/3765 (34%)]\tLoss: 0.000314\n",
      "Train Epoch: 7 [1920/3765 (51%)]\tLoss: 0.003345\n",
      "Train Epoch: 7 [2560/3765 (68%)]\tLoss: 0.162772\n",
      "Train Epoch: 7 [3200/3765 (85%)]\tLoss: 0.089141\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1494/1506 (99%)\n",
      "\n",
      "New best model saved with accuracy: 99.20318725099601\n",
      "Train Epoch: 8 [0/3765 (0%)]\tLoss: 0.011632\n",
      "Train Epoch: 8 [640/3765 (17%)]\tLoss: 0.037266\n",
      "Train Epoch: 8 [1280/3765 (34%)]\tLoss: 0.001512\n",
      "Train Epoch: 8 [1920/3765 (51%)]\tLoss: 0.022839\n",
      "Train Epoch: 8 [2560/3765 (68%)]\tLoss: 0.001212\n",
      "Train Epoch: 8 [3200/3765 (85%)]\tLoss: 0.006830\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 1499/1506 (100%)\n",
      "\n",
      "New best model saved with accuracy: 99.53519256308101\n",
      "Train Epoch: 9 [0/3765 (0%)]\tLoss: 0.016768\n",
      "Train Epoch: 9 [640/3765 (17%)]\tLoss: 0.014985\n",
      "Train Epoch: 9 [1280/3765 (34%)]\tLoss: 0.003801\n",
      "Train Epoch: 9 [1920/3765 (51%)]\tLoss: 0.023719\n",
      "Train Epoch: 9 [2560/3765 (68%)]\tLoss: 0.358023\n",
      "Train Epoch: 9 [3200/3765 (85%)]\tLoss: 0.015623\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 1498/1506 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/3765 (0%)]\tLoss: 0.107367\n",
      "Train Epoch: 10 [640/3765 (17%)]\tLoss: 0.042749\n",
      "Train Epoch: 10 [1280/3765 (34%)]\tLoss: 0.022850\n",
      "Train Epoch: 10 [1920/3765 (51%)]\tLoss: 0.042931\n",
      "Train Epoch: 10 [2560/3765 (68%)]\tLoss: 0.019884\n",
      "Train Epoch: 10 [3200/3765 (85%)]\tLoss: 0.008504\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 1497/1506 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/3765 (0%)]\tLoss: 0.001420\n",
      "Train Epoch: 11 [640/3765 (17%)]\tLoss: 0.038063\n",
      "Train Epoch: 11 [1280/3765 (34%)]\tLoss: 0.003253\n",
      "Train Epoch: 11 [1920/3765 (51%)]\tLoss: 0.001980\n",
      "Train Epoch: 11 [2560/3765 (68%)]\tLoss: 0.028767\n",
      "Train Epoch: 11 [3200/3765 (85%)]\tLoss: 0.006618\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1494/1506 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/3765 (0%)]\tLoss: 0.007895\n",
      "Train Epoch: 12 [640/3765 (17%)]\tLoss: 0.088752\n",
      "Train Epoch: 12 [1280/3765 (34%)]\tLoss: 0.000644\n",
      "Train Epoch: 12 [1920/3765 (51%)]\tLoss: 0.000814\n",
      "Train Epoch: 12 [2560/3765 (68%)]\tLoss: 0.024469\n",
      "Train Epoch: 12 [3200/3765 (85%)]\tLoss: 0.009392\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1496/1506 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/3765 (0%)]\tLoss: 0.001990\n",
      "Train Epoch: 13 [640/3765 (17%)]\tLoss: 0.000814\n",
      "Train Epoch: 13 [1280/3765 (34%)]\tLoss: 0.000972\n",
      "Train Epoch: 13 [1920/3765 (51%)]\tLoss: 0.015553\n",
      "Train Epoch: 13 [2560/3765 (68%)]\tLoss: 0.064565\n",
      "Train Epoch: 13 [3200/3765 (85%)]\tLoss: 0.165181\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 1495/1506 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/3765 (0%)]\tLoss: 0.109757\n",
      "Train Epoch: 14 [640/3765 (17%)]\tLoss: 0.000820\n",
      "Train Epoch: 14 [1280/3765 (34%)]\tLoss: 0.007438\n",
      "Train Epoch: 14 [1920/3765 (51%)]\tLoss: 0.000871\n",
      "Train Epoch: 14 [2560/3765 (68%)]\tLoss: 0.032066\n",
      "Train Epoch: 14 [3200/3765 (85%)]\tLoss: 0.009270\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 1495/1506 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/3765 (0%)]\tLoss: 0.002602\n",
      "Train Epoch: 15 [640/3765 (17%)]\tLoss: 0.051521\n",
      "Train Epoch: 15 [1280/3765 (34%)]\tLoss: 0.054180\n",
      "Train Epoch: 15 [1920/3765 (51%)]\tLoss: 0.003386\n",
      "Train Epoch: 15 [2560/3765 (68%)]\tLoss: 0.205836\n",
      "Train Epoch: 15 [3200/3765 (85%)]\tLoss: 0.000060\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 1484/1506 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/3765 (0%)]\tLoss: 0.006376\n",
      "Train Epoch: 16 [640/3765 (17%)]\tLoss: 0.003445\n",
      "Train Epoch: 16 [1280/3765 (34%)]\tLoss: 0.002713\n",
      "Train Epoch: 16 [1920/3765 (51%)]\tLoss: 0.001382\n",
      "Train Epoch: 16 [2560/3765 (68%)]\tLoss: 0.047551\n",
      "Train Epoch: 16 [3200/3765 (85%)]\tLoss: 0.146010\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1493/1506 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/3765 (0%)]\tLoss: 0.000109\n",
      "Train Epoch: 17 [640/3765 (17%)]\tLoss: 0.000473\n",
      "Train Epoch: 17 [1280/3765 (34%)]\tLoss: 0.007077\n",
      "Train Epoch: 17 [1920/3765 (51%)]\tLoss: 0.002658\n",
      "Train Epoch: 17 [2560/3765 (68%)]\tLoss: 0.025743\n",
      "Train Epoch: 17 [3200/3765 (85%)]\tLoss: 0.021631\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1487/1506 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/3765 (0%)]\tLoss: 0.000851\n",
      "Train Epoch: 18 [640/3765 (17%)]\tLoss: 0.000151\n",
      "Train Epoch: 18 [1280/3765 (34%)]\tLoss: 0.088047\n",
      "Train Epoch: 18 [1920/3765 (51%)]\tLoss: 1.572462\n",
      "Train Epoch: 18 [2560/3765 (68%)]\tLoss: 0.000281\n",
      "Train Epoch: 18 [3200/3765 (85%)]\tLoss: 0.032145\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 1499/1506 (100%)\n",
      "\n",
      "Train Epoch: 19 [0/3765 (0%)]\tLoss: 0.313804\n",
      "Train Epoch: 19 [640/3765 (17%)]\tLoss: 0.002423\n",
      "Train Epoch: 19 [1280/3765 (34%)]\tLoss: 0.002266\n",
      "Train Epoch: 19 [1920/3765 (51%)]\tLoss: 0.000179\n",
      "Train Epoch: 19 [2560/3765 (68%)]\tLoss: 0.000601\n",
      "Train Epoch: 19 [3200/3765 (85%)]\tLoss: 0.014049\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1501/1506 (100%)\n",
      "\n",
      "New best model saved with accuracy: 99.66799468791501\n",
      "Train Epoch: 20 [0/3765 (0%)]\tLoss: 0.000780\n",
      "Train Epoch: 20 [640/3765 (17%)]\tLoss: 0.000905\n",
      "Train Epoch: 20 [1280/3765 (34%)]\tLoss: 0.000519\n",
      "Train Epoch: 20 [1920/3765 (51%)]\tLoss: 0.113100\n",
      "Train Epoch: 20 [2560/3765 (68%)]\tLoss: 0.000718\n",
      "Train Epoch: 20 [3200/3765 (85%)]\tLoss: 0.000080\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1489/1506 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/3765 (0%)]\tLoss: 0.049659\n",
      "Train Epoch: 21 [640/3765 (17%)]\tLoss: 0.001548\n",
      "Train Epoch: 21 [1280/3765 (34%)]\tLoss: 0.000157\n",
      "Train Epoch: 21 [1920/3765 (51%)]\tLoss: 0.002665\n",
      "Train Epoch: 21 [2560/3765 (68%)]\tLoss: 0.058472\n",
      "Train Epoch: 21 [3200/3765 (85%)]\tLoss: 0.005979\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1497/1506 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/3765 (0%)]\tLoss: 0.013313\n",
      "Train Epoch: 22 [640/3765 (17%)]\tLoss: 0.000305\n",
      "Train Epoch: 22 [1280/3765 (34%)]\tLoss: 0.004238\n",
      "Train Epoch: 22 [1920/3765 (51%)]\tLoss: 0.002185\n",
      "Train Epoch: 22 [2560/3765 (68%)]\tLoss: 0.005592\n",
      "Train Epoch: 22 [3200/3765 (85%)]\tLoss: 0.011324\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1493/1506 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/3765 (0%)]\tLoss: 0.076298\n",
      "Train Epoch: 23 [640/3765 (17%)]\tLoss: 0.000356\n",
      "Train Epoch: 23 [1280/3765 (34%)]\tLoss: 0.001641\n",
      "Train Epoch: 23 [1920/3765 (51%)]\tLoss: 0.002075\n",
      "Train Epoch: 23 [2560/3765 (68%)]\tLoss: 0.012432\n",
      "Train Epoch: 23 [3200/3765 (85%)]\tLoss: 0.003722\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1496/1506 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/3765 (0%)]\tLoss: 0.000046\n",
      "Train Epoch: 24 [640/3765 (17%)]\tLoss: 0.000396\n",
      "Train Epoch: 24 [1280/3765 (34%)]\tLoss: 0.000891\n",
      "Train Epoch: 24 [1920/3765 (51%)]\tLoss: 0.026665\n",
      "Train Epoch: 24 [2560/3765 (68%)]\tLoss: 0.119650\n",
      "Train Epoch: 24 [3200/3765 (85%)]\tLoss: 0.002366\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 1496/1506 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/3765 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 25 [640/3765 (17%)]\tLoss: 0.029713\n",
      "Train Epoch: 25 [1280/3765 (34%)]\tLoss: 0.098931\n",
      "Train Epoch: 25 [1920/3765 (51%)]\tLoss: 0.042873\n",
      "Train Epoch: 25 [2560/3765 (68%)]\tLoss: 0.086977\n",
      "Train Epoch: 25 [3200/3765 (85%)]\tLoss: 0.005834\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1490/1506 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/3765 (0%)]\tLoss: 0.195381\n",
      "Train Epoch: 26 [640/3765 (17%)]\tLoss: 0.032884\n",
      "Train Epoch: 26 [1280/3765 (34%)]\tLoss: 0.000111\n",
      "Train Epoch: 26 [1920/3765 (51%)]\tLoss: 0.000203\n",
      "Train Epoch: 26 [2560/3765 (68%)]\tLoss: 0.024949\n",
      "Train Epoch: 26 [3200/3765 (85%)]\tLoss: 0.061562\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1497/1506 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/3765 (0%)]\tLoss: 0.000507\n",
      "Train Epoch: 27 [640/3765 (17%)]\tLoss: 0.000605\n",
      "Train Epoch: 27 [1280/3765 (34%)]\tLoss: 0.000952\n",
      "Train Epoch: 27 [1920/3765 (51%)]\tLoss: 0.027121\n",
      "Train Epoch: 27 [2560/3765 (68%)]\tLoss: 1.562540\n",
      "Train Epoch: 27 [3200/3765 (85%)]\tLoss: 0.061678\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 1457/1506 (97%)\n",
      "\n",
      "Train Epoch: 28 [0/3765 (0%)]\tLoss: 0.208788\n",
      "Train Epoch: 28 [640/3765 (17%)]\tLoss: 0.000699\n",
      "Train Epoch: 28 [1280/3765 (34%)]\tLoss: 0.000085\n",
      "Train Epoch: 28 [1920/3765 (51%)]\tLoss: 0.001197\n",
      "Train Epoch: 28 [2560/3765 (68%)]\tLoss: 0.000126\n",
      "Train Epoch: 28 [3200/3765 (85%)]\tLoss: 0.000112\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1495/1506 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/3765 (0%)]\tLoss: 0.003938\n",
      "Train Epoch: 29 [640/3765 (17%)]\tLoss: 0.000225\n",
      "Train Epoch: 29 [1280/3765 (34%)]\tLoss: 0.000112\n",
      "Train Epoch: 29 [1920/3765 (51%)]\tLoss: 0.000409\n",
      "Train Epoch: 29 [2560/3765 (68%)]\tLoss: 0.000892\n",
      "Train Epoch: 29 [3200/3765 (85%)]\tLoss: 0.000076\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1502/1506 (100%)\n",
      "\n",
      "New best model saved with accuracy: 99.734395750332\n",
      "Train Epoch: 30 [0/3765 (0%)]\tLoss: 0.001690\n",
      "Train Epoch: 30 [640/3765 (17%)]\tLoss: 0.183396\n",
      "Train Epoch: 30 [1280/3765 (34%)]\tLoss: 0.004965\n",
      "Train Epoch: 30 [1920/3765 (51%)]\tLoss: 0.001897\n",
      "Train Epoch: 30 [2560/3765 (68%)]\tLoss: 0.000432\n",
      "Train Epoch: 30 [3200/3765 (85%)]\tLoss: 0.003239\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1501/1506 (100%)\n",
      "\n",
      "Train Epoch: 31 [0/3765 (0%)]\tLoss: 0.000104\n",
      "Train Epoch: 31 [640/3765 (17%)]\tLoss: 0.031205\n",
      "Train Epoch: 31 [1280/3765 (34%)]\tLoss: 0.003820\n",
      "Train Epoch: 31 [1920/3765 (51%)]\tLoss: 0.011449\n",
      "Train Epoch: 31 [2560/3765 (68%)]\tLoss: 0.005767\n",
      "Train Epoch: 31 [3200/3765 (85%)]\tLoss: 0.002476\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 1473/1506 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/3765 (0%)]\tLoss: 0.003313\n",
      "Train Epoch: 32 [640/3765 (17%)]\tLoss: 0.009955\n",
      "Train Epoch: 32 [1280/3765 (34%)]\tLoss: 0.003516\n",
      "Train Epoch: 32 [1920/3765 (51%)]\tLoss: 0.016429\n",
      "Train Epoch: 32 [2560/3765 (68%)]\tLoss: 0.005746\n",
      "Train Epoch: 32 [3200/3765 (85%)]\tLoss: 0.004887\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1493/1506 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/3765 (0%)]\tLoss: 0.001644\n",
      "Train Epoch: 33 [640/3765 (17%)]\tLoss: 0.000765\n",
      "Train Epoch: 33 [1280/3765 (34%)]\tLoss: 0.000320\n",
      "Train Epoch: 33 [1920/3765 (51%)]\tLoss: 0.060723\n",
      "Train Epoch: 33 [2560/3765 (68%)]\tLoss: 0.020311\n",
      "Train Epoch: 33 [3200/3765 (85%)]\tLoss: 0.004928\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1497/1506 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/3765 (0%)]\tLoss: 0.002733\n",
      "Train Epoch: 34 [640/3765 (17%)]\tLoss: 0.034196\n",
      "Train Epoch: 34 [1280/3765 (34%)]\tLoss: 0.016248\n",
      "Train Epoch: 34 [1920/3765 (51%)]\tLoss: 0.012396\n",
      "Train Epoch: 34 [2560/3765 (68%)]\tLoss: 0.000438\n",
      "Train Epoch: 34 [3200/3765 (85%)]\tLoss: 0.005284\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1499/1506 (100%)\n",
      "\n",
      "Train Epoch: 35 [0/3765 (0%)]\tLoss: 0.043483\n",
      "Train Epoch: 35 [640/3765 (17%)]\tLoss: 0.015083\n",
      "Train Epoch: 35 [1280/3765 (34%)]\tLoss: 0.011411\n",
      "Train Epoch: 35 [1920/3765 (51%)]\tLoss: 0.013839\n",
      "Train Epoch: 35 [2560/3765 (68%)]\tLoss: 0.024112\n",
      "Train Epoch: 35 [3200/3765 (85%)]\tLoss: 0.016236\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1494/1506 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/3765 (0%)]\tLoss: 0.006790\n",
      "Train Epoch: 36 [640/3765 (17%)]\tLoss: 0.140579\n",
      "Train Epoch: 36 [1280/3765 (34%)]\tLoss: 0.000858\n",
      "Train Epoch: 36 [1920/3765 (51%)]\tLoss: 0.014409\n",
      "Train Epoch: 36 [2560/3765 (68%)]\tLoss: 0.000221\n",
      "Train Epoch: 36 [3200/3765 (85%)]\tLoss: 0.002636\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1495/1506 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/3765 (0%)]\tLoss: 0.000143\n",
      "Train Epoch: 37 [640/3765 (17%)]\tLoss: 0.011430\n",
      "Train Epoch: 37 [1280/3765 (34%)]\tLoss: 0.004051\n",
      "Train Epoch: 37 [1920/3765 (51%)]\tLoss: 0.000297\n",
      "Train Epoch: 37 [2560/3765 (68%)]\tLoss: 0.025389\n",
      "Train Epoch: 37 [3200/3765 (85%)]\tLoss: 0.000144\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1502/1506 (100%)\n",
      "\n",
      "Train Epoch: 38 [0/3765 (0%)]\tLoss: 0.000845\n",
      "Train Epoch: 38 [640/3765 (17%)]\tLoss: 0.012139\n",
      "Train Epoch: 38 [1280/3765 (34%)]\tLoss: 0.068806\n",
      "Train Epoch: 38 [1920/3765 (51%)]\tLoss: 0.346471\n",
      "Train Epoch: 38 [2560/3765 (68%)]\tLoss: 0.049499\n",
      "Train Epoch: 38 [3200/3765 (85%)]\tLoss: 0.006198\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1497/1506 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/3765 (0%)]\tLoss: 0.028872\n",
      "Train Epoch: 39 [640/3765 (17%)]\tLoss: 0.088855\n",
      "Train Epoch: 39 [1280/3765 (34%)]\tLoss: 0.000420\n",
      "Train Epoch: 39 [1920/3765 (51%)]\tLoss: 0.024184\n",
      "Train Epoch: 39 [2560/3765 (68%)]\tLoss: 0.000157\n",
      "Train Epoch: 39 [3200/3765 (85%)]\tLoss: 0.000103\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1499/1506 (100%)\n",
      "\n",
      "Train Epoch: 40 [0/3765 (0%)]\tLoss: 0.001891\n",
      "Train Epoch: 40 [640/3765 (17%)]\tLoss: 0.000019\n",
      "Train Epoch: 40 [1280/3765 (34%)]\tLoss: 0.000017\n",
      "Train Epoch: 40 [1920/3765 (51%)]\tLoss: 0.000115\n",
      "Train Epoch: 40 [2560/3765 (68%)]\tLoss: 0.000020\n",
      "Train Epoch: 40 [3200/3765 (85%)]\tLoss: 0.009874\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1495/1506 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/3765 (0%)]\tLoss: 0.000655\n",
      "Train Epoch: 41 [640/3765 (17%)]\tLoss: 0.007535\n",
      "Train Epoch: 41 [1280/3765 (34%)]\tLoss: 0.000074\n",
      "Train Epoch: 41 [1920/3765 (51%)]\tLoss: 0.002962\n",
      "Train Epoch: 41 [2560/3765 (68%)]\tLoss: 0.002861\n",
      "Train Epoch: 41 [3200/3765 (85%)]\tLoss: 0.090320\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 1486/1506 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/3765 (0%)]\tLoss: 0.020201\n",
      "Train Epoch: 42 [640/3765 (17%)]\tLoss: 0.063105\n",
      "Train Epoch: 42 [1280/3765 (34%)]\tLoss: 0.000272\n",
      "Train Epoch: 42 [1920/3765 (51%)]\tLoss: 0.018812\n",
      "Train Epoch: 42 [2560/3765 (68%)]\tLoss: 0.000260\n",
      "Train Epoch: 42 [3200/3765 (85%)]\tLoss: 0.004710\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1496/1506 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/3765 (0%)]\tLoss: 0.009865\n",
      "Train Epoch: 43 [640/3765 (17%)]\tLoss: 0.136646\n",
      "Train Epoch: 43 [1280/3765 (34%)]\tLoss: 0.000013\n",
      "Train Epoch: 43 [1920/3765 (51%)]\tLoss: 0.000491\n",
      "Train Epoch: 43 [2560/3765 (68%)]\tLoss: 0.000517\n",
      "Train Epoch: 43 [3200/3765 (85%)]\tLoss: 0.000516\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1502/1506 (100%)\n",
      "\n",
      "Train Epoch: 44 [0/3765 (0%)]\tLoss: 0.000038\n",
      "Train Epoch: 44 [640/3765 (17%)]\tLoss: 0.000814\n",
      "Train Epoch: 44 [1280/3765 (34%)]\tLoss: 0.003194\n",
      "Train Epoch: 44 [1920/3765 (51%)]\tLoss: 0.000244\n",
      "Train Epoch: 44 [2560/3765 (68%)]\tLoss: 0.000180\n",
      "Train Epoch: 44 [3200/3765 (85%)]\tLoss: 0.000113\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1502/1506 (100%)\n",
      "\n",
      "Train Epoch: 45 [0/3765 (0%)]\tLoss: 0.001979\n",
      "Train Epoch: 45 [640/3765 (17%)]\tLoss: 0.002649\n",
      "Train Epoch: 45 [1280/3765 (34%)]\tLoss: 0.000341\n",
      "Train Epoch: 45 [1920/3765 (51%)]\tLoss: 0.000363\n",
      "Train Epoch: 45 [2560/3765 (68%)]\tLoss: 0.010789\n",
      "Train Epoch: 45 [3200/3765 (85%)]\tLoss: 0.000489\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1500/1506 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/3765 (0%)]\tLoss: 0.000021\n",
      "Train Epoch: 46 [640/3765 (17%)]\tLoss: 0.001778\n",
      "Train Epoch: 46 [1280/3765 (34%)]\tLoss: 0.002627\n",
      "Train Epoch: 46 [1920/3765 (51%)]\tLoss: 0.000023\n",
      "Train Epoch: 46 [2560/3765 (68%)]\tLoss: 0.000047\n",
      "Train Epoch: 46 [3200/3765 (85%)]\tLoss: 0.055279\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1489/1506 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/3765 (0%)]\tLoss: 0.037488\n",
      "Train Epoch: 47 [640/3765 (17%)]\tLoss: 0.001190\n",
      "Train Epoch: 47 [1280/3765 (34%)]\tLoss: 0.001367\n",
      "Train Epoch: 47 [1920/3765 (51%)]\tLoss: 0.083502\n",
      "Train Epoch: 47 [2560/3765 (68%)]\tLoss: 0.000572\n",
      "Train Epoch: 47 [3200/3765 (85%)]\tLoss: 0.000065\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 1500/1506 (100%)\n",
      "\n",
      "Train Epoch: 48 [0/3765 (0%)]\tLoss: 0.000016\n",
      "Train Epoch: 48 [640/3765 (17%)]\tLoss: 0.000065\n",
      "Train Epoch: 48 [1280/3765 (34%)]\tLoss: 0.124325\n",
      "Train Epoch: 48 [1920/3765 (51%)]\tLoss: 0.000204\n",
      "Train Epoch: 48 [2560/3765 (68%)]\tLoss: 0.000208\n",
      "Train Epoch: 48 [3200/3765 (85%)]\tLoss: 0.000294\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 1489/1506 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/3765 (0%)]\tLoss: 0.000291\n",
      "Train Epoch: 49 [640/3765 (17%)]\tLoss: 0.000489\n",
      "Train Epoch: 49 [1280/3765 (34%)]\tLoss: 0.000385\n",
      "Train Epoch: 49 [1920/3765 (51%)]\tLoss: 0.000744\n",
      "Train Epoch: 49 [2560/3765 (68%)]\tLoss: 0.001041\n",
      "Train Epoch: 49 [3200/3765 (85%)]\tLoss: 0.000310\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 1501/1506 (100%)\n",
      "\n",
      "Train Epoch: 50 [0/3765 (0%)]\tLoss: 1.563169\n",
      "Train Epoch: 50 [640/3765 (17%)]\tLoss: 0.001466\n",
      "Train Epoch: 50 [1280/3765 (34%)]\tLoss: 0.000617\n",
      "Train Epoch: 50 [1920/3765 (51%)]\tLoss: 0.149924\n",
      "Train Epoch: 50 [2560/3765 (68%)]\tLoss: 0.186154\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    batch_size = 64\n",
    "    test_batch_size = 500\n",
    "    epochs = 50\n",
    "    learning_rate = .001\n",
    "    no_cuda = True\n",
    "    dry_run = False\n",
    "    seed = random.randint(1,1000)\n",
    "    log_interval = 10\n",
    "    save_model = False \n",
    "    \n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    use_cuda = no_cuda\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    val_kwargs = {'batch_size': test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        val_kwargs.update(cuda_kwargs)\n",
    " \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.2404, 0.2967, 0.3563], [0.0547, 0.0527, 0.0477])\n",
    "        ])\n",
    "    \n",
    "    # Create train and test set\n",
    "    path_to_dataset = \"/courses/CS5330.202450/data/Boat-MNIST\" # You need to change this to the path where you have the dataset\n",
    "    train_set = Boats(root_dir=path_to_dataset + \"/train\", transform=transform,\n",
    "                      gt_json_path=path_to_dataset + \"/boat_mnist_labels_trainval.json\")\n",
    "    val_set = Boats(root_dir=path_to_dataset + \"/val\", transform=transform,\n",
    "                    gt_json_path=path_to_dataset +\"/boat_mnist_labels_trainval.json\")\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(val_set, **val_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    total_params = count_parameters(model)\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    best_acc = 0\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(log_interval, model, device, train_loader, optimizer, criterion, epoch, dry_run)\n",
    "        acc = test(model, device, test_loader, criterion)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            save_my_model(model, \"models/best_model.pth\")\n",
    "            print(f\"New best model saved with accuracy: {best_acc}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total training and evaluation time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"Best accuracy (val): {best_acc}\")\n",
    "\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "    \n",
    "\n",
    "    dummy_input = torch.randn(1, 3, 108, 192, device=device)\n",
    "    input_names = [\"img_1\"]\n",
    "    output_names = [\"output1\"]\n",
    "    torch.onnx.export(model, dummy_input, \"models/ship_example.onnx\", input_names=input_names, output_names=output_names)\n",
    "\n",
    "if __name__ == '__main__':\n",
    " main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
