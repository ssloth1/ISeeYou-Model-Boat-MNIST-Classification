{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# James Bebarski\n",
    "# Computer Vision\n",
    "# Boat MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boats(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, gt_json_path=''):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.gt_json_path = gt_json_path\n",
    "        self.labels = json.load(open(gt_json_path, 'r'))\n",
    "        self.image_list = sorted(os.listdir(root_dir))\n",
    "        self.image_ids = dict(enumerate(self.image_list, start=0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.load_image(idx)\n",
    "        img_name = self.image_ids[idx]\n",
    "        label = self.labels[img_name]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        sample = (img, label)\n",
    "        return sample\n",
    "\n",
    "    def load_image(self, image_index):\n",
    "        image_name = self.image_ids[image_index]\n",
    "        path = os.path.join(self.root_dir, image_name)\n",
    "        img = imread(path)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(512 * 6 * 12, 512)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "        \n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, criterion, epoch,dry_run):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.unsqueeze(target, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    misclassified_images = []\n",
    "    misclassified_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device).float()\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, torch.unsqueeze(target, 1)).item()\n",
    "            pred = torch.round(output)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            incorrect_indices = (pred != target.view_as(pred)).nonzero(as_tuple=True)[0]\n",
    "            misclassified_images.extend(data[incorrect_indices].cpu())\n",
    "            misclassified_labels.extend(target[incorrect_indices].cpu())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def save_my_model(model, path):\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    torch.save(model.state_dict(), path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 20428289\n",
      "Train Epoch: 1 [0/3765 (0%)]\tLoss: 0.715955\n",
      "Train Epoch: 1 [640/3765 (17%)]\tLoss: 4.798062\n",
      "Train Epoch: 1 [1280/3765 (34%)]\tLoss: 3.344305\n",
      "Train Epoch: 1 [1920/3765 (51%)]\tLoss: 4.965849\n",
      "Train Epoch: 1 [2560/3765 (68%)]\tLoss: 7.875897\n",
      "Train Epoch: 1 [3200/3765 (85%)]\tLoss: 4.692716\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 1408/1506 (93%)\n",
      "\n",
      "New best model saved with accuracy: 93.49269588313413\n",
      "Train Epoch: 2 [0/3765 (0%)]\tLoss: 4.706879\n",
      "Train Epoch: 2 [640/3765 (17%)]\tLoss: 2.471151\n",
      "Train Epoch: 2 [1280/3765 (34%)]\tLoss: 0.071635\n",
      "Train Epoch: 2 [1920/3765 (51%)]\tLoss: 0.116288\n",
      "Train Epoch: 2 [2560/3765 (68%)]\tLoss: 3.222352\n",
      "Train Epoch: 2 [3200/3765 (85%)]\tLoss: 3.460320\n",
      "\n",
      "Test set: Average loss: 0.0408, Accuracy: 1329/1506 (88%)\n",
      "\n",
      "Train Epoch: 3 [0/3765 (0%)]\tLoss: 0.164523\n",
      "Train Epoch: 3 [640/3765 (17%)]\tLoss: 0.107897\n",
      "Train Epoch: 3 [1280/3765 (34%)]\tLoss: 0.023057\n",
      "Train Epoch: 3 [1920/3765 (51%)]\tLoss: 0.142457\n",
      "Train Epoch: 3 [2560/3765 (68%)]\tLoss: 1.664052\n",
      "Train Epoch: 3 [3200/3765 (85%)]\tLoss: 1.980614\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 1458/1506 (97%)\n",
      "\n",
      "New best model saved with accuracy: 96.81274900398407\n",
      "Train Epoch: 4 [0/3765 (0%)]\tLoss: 4.738611\n",
      "Train Epoch: 4 [640/3765 (17%)]\tLoss: 0.474942\n",
      "Train Epoch: 4 [1280/3765 (34%)]\tLoss: 0.081964\n",
      "Train Epoch: 4 [1920/3765 (51%)]\tLoss: 1.738620\n",
      "Train Epoch: 4 [2560/3765 (68%)]\tLoss: 1.964420\n",
      "Train Epoch: 4 [3200/3765 (85%)]\tLoss: 0.513383\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 1453/1506 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/3765 (0%)]\tLoss: 5.051746\n",
      "Train Epoch: 5 [640/3765 (17%)]\tLoss: 0.645247\n",
      "Train Epoch: 5 [1280/3765 (34%)]\tLoss: 0.007551\n",
      "Train Epoch: 5 [1920/3765 (51%)]\tLoss: 1.639707\n",
      "Train Epoch: 5 [2560/3765 (68%)]\tLoss: 3.567046\n",
      "Train Epoch: 5 [3200/3765 (85%)]\tLoss: 0.001768\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 1485/1506 (99%)\n",
      "\n",
      "New best model saved with accuracy: 98.60557768924303\n",
      "Train Epoch: 6 [0/3765 (0%)]\tLoss: 0.282434\n",
      "Train Epoch: 6 [640/3765 (17%)]\tLoss: 0.004784\n",
      "Train Epoch: 6 [1280/3765 (34%)]\tLoss: 0.005266\n",
      "Train Epoch: 6 [1920/3765 (51%)]\tLoss: 1.880234\n",
      "Train Epoch: 6 [2560/3765 (68%)]\tLoss: 1.564617\n",
      "Train Epoch: 6 [3200/3765 (85%)]\tLoss: 0.119123\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 1482/1506 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/3765 (0%)]\tLoss: 0.111894\n",
      "Train Epoch: 7 [640/3765 (17%)]\tLoss: 0.115420\n",
      "Train Epoch: 7 [1280/3765 (34%)]\tLoss: 1.571269\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # It is worth noting that I used 28 in my implementation\n",
    "    # it took me about 13 minutes to generate\n",
    "    \n",
    "    batch_size = 64\n",
    "    test_batch_size = 500\n",
    "    epochs = 50\n",
    "    learning_rate = .001\n",
    "    no_cuda = True\n",
    "    dry_run = False\n",
    "    seed = random.randint(1,1000)\n",
    "    log_interval = 10\n",
    "    save_model = False \n",
    "    \n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    use_cuda = no_cuda\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    val_kwargs = {'batch_size': test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        val_kwargs.update(cuda_kwargs)\n",
    " \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.2404, 0.2967, 0.3563], [0.0547, 0.0527, 0.0477])\n",
    "        ])\n",
    "    \n",
    "    # This was the path I used for my dataset, however, you'll need to change this to your own path\n",
    "    path_to_dataset = \"/courses/CS5330.202450/data/Boat-MNIST\"\n",
    "    train_set = Boats(root_dir=path_to_dataset + \"/train\", transform=transform,\n",
    "                      gt_json_path=path_to_dataset + \"/boat_mnist_labels_trainval.json\")\n",
    "    val_set = Boats(root_dir=path_to_dataset + \"/val\", transform=transform,\n",
    "                    gt_json_path=path_to_dataset +\"/boat_mnist_labels_trainval.json\")\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(val_set, **val_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "    total_params = count_parameters(model)\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train and validate\n",
    "    best_acc = 0\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(log_interval, model, device, train_loader, optimizer, criterion, epoch, dry_run)\n",
    "        acc = test(model, device, test_loader, criterion)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            save_my_model(model, \"models/best_model.pth\")\n",
    "            print(f\"New best model saved with accuracy: {best_acc}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total training and evaluation time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"Best accuracy (val): {best_acc}\")\n",
    "\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "    dummy_input = torch.randn(1, 3, 108, 192, device=device)\n",
    "    input_names = [\"img_1\"]\n",
    "    output_names = [\"output1\"]\n",
    "    torch.onnx.export(model, dummy_input, \"models/ship_example.onnx\", input_names=input_names, output_names=output_names)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
